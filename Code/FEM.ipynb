{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast: 2, Size: 16, Problem: <FEMhelper.femHelper.Problem object at 0x7f126253bf50>\n",
      "Solving linear variational problem.\n",
      "Solving linear variational problem.\n",
      "Solving linear variational problem.\n",
      "Solving linear variational problem.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContrast: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontrast_ratio[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrast_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_size[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize_image\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Problem: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproblem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproblem\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[0;32m---> 44\u001b[0m \u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasetsFNO/imageSizes/imageSize=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimage_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msize_image\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/Radu Vasilache/Documents/StudiumTUM/Bachelorarbeit/Code/FEMhelper/datasetHelper.py:79\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(save_path, num_samples, problem, **material_params)\u001b[0m\n\u001b[1;32m     77\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_path_res, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m np\u001b[38;5;241m.\u001b[39msave(input_file, updated_input_data)\n\u001b[0;32m---> 79\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdated_output_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fenicsproject/lib/python3.11/site-packages/numpy/lib/npyio.py:546\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_imports\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fenicsproject/lib/python3.11/site-packages/numpy/lib/format.py:730\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m--> 730\u001b[0m         \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[1;32m    733\u001b[0m                 array, flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexternal_loop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffered\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerosize_ok\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    734\u001b[0m                 buffersize\u001b[38;5;241m=\u001b[39mbuffersize, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from FEMhelper.datasetHelper import create_dataset\n",
    "from FEMhelper.femHelper import Problem\n",
    "from FEMhelper.bc import f, bcX0, bcX1, bcY0, bcY1\n",
    "\n",
    "# Just for the initial case\n",
    "lamb=1\n",
    "mu=0.5\n",
    "nu_example = lamb/ (2*lamb + 2*mu)\n",
    "E_example = mu * 2*(1+nu_example)\n",
    "\n",
    "# List of materials parameters\n",
    "set_materials_params = [\n",
    "    {'E_1': 1, 'nu': 0.3, 'contrast_ratio': 0.5, 'size_image': 32}\n",
    "]\n",
    "\n",
    "# List of problems\n",
    "p0 = Problem(f, bcX0, bcX1, bcY0, bcY1)\n",
    "problems = [\n",
    "    {'problem': p0},\n",
    "    {'problem': 'p1'},\n",
    "    {'problem': 'p2'},\n",
    "]\n",
    "\n",
    "contrastRatioConfigs = [\n",
    "    {\"contrast_ratio\": 2},\n",
    "    {\"contrast_ratio\": 50},\n",
    "    {\"contrast_ratio\": 100},\n",
    "    {\"contrast_ratio\": 500},\n",
    "]\n",
    "\n",
    "imageSizeConfigs = [\n",
    "    {\"size_image\": 16},\n",
    "    {\"size_image\": 32},\n",
    "    {\"size_image\": 64},\n",
    "    {\"size_image\": 128},\n",
    "]\n",
    "\n",
    "for contrast_ratio in contrastRatioConfigs[:1]:\n",
    "    for image_size in imageSizeConfigs:\n",
    "        for problem in problems[:1]:\n",
    "            config = {**problem, **contrast_ratio, **image_size}\n",
    "            name = f\"Contrast: {contrast_ratio['contrast_ratio']}, Size: {image_size['size_image']}, Problem: {problem['problem']}\"\n",
    "            print(name)\n",
    "            create_dataset(save_path=f\"datasetsFNO/imageSizes/imageSize={image_size['size_image']}\", num_samples= 1000, **config)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64, 64, 3)\n",
      "(16, 64, 64, 6)\n",
      "(540, 64, 64, 3)\n",
      "(540, 64, 64, 6)\n",
      "(500, 64, 64, 3)\n",
      "(500, 64, 64, 6)\n",
      "(500, 64, 64, 3)\n",
      "(500, 64, 64, 6)\n",
      "(500, 64, 64, 3)\n",
      "(500, 64, 64, 6)\n"
     ]
    }
   ],
   "source": [
    "from FEMhelper.plot import inquire\n",
    "inquire('datasetsFNO/imageSizes/imageSize=16/64_64')\n",
    "inquire('datasetsFNO/contrast_ratios/CR=2/64_64')\n",
    "inquire('datasetsFNO/contrast_ratios/CR=50/64_64')\n",
    "inquire('datasetsFNO/contrast_ratios/CR=100/64_64')\n",
    "inquire('datasetsFNO/contrast_ratios/CR=500/64_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 91684044 into shape (541,256,256,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasetsFNO/256_256/output_data.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/fenicsproject/lib/python3.11/site-packages/numpy/lib/npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/anaconda3/envs/fenicsproject/lib/python3.11/site-packages/numpy/lib/format.py:839\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    837\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 839\u001b[0m         \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m=\u001b[39m shape\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 91684044 into shape (541,256,256,6)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "output_data = np.load('datasetsFNO/256_256/output_data.npy')\n",
    "print(output_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 3, the array at index 0 has size 6 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     dest_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(dest_file_path)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Concatenate source data to destination data\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     combined_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# If destination file does not exist, use source data as combined data\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     combined_data \u001b[38;5;241m=\u001b[39m source_data\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 3, the array at index 0 has size 6 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Path to the datasetsFNO directory\n",
    "datasets_path_dest = 'datasetsFNO'\n",
    "datasets_path_source = 'datasetsFNO/test2'\n",
    "# Iterate over the folder names in datasetsFNO\n",
    "for folder_name in os.listdir(datasets_path_source):\n",
    "    source_folder_path = os.path.join(datasets_path_source, folder_name)\n",
    "    dest_folder_path = os.path.join(datasets_path_dest, folder_name)\n",
    "\n",
    "    for file_name in os.listdir(source_folder_path):\n",
    "        source_file_path = os.path.join(source_folder_path, file_name)\n",
    "        dest_file_path = os.path.join(dest_folder_path, file_name)\n",
    "        if os.path.isfile(source_file_path):\n",
    "            # Load data from source file\n",
    "            source_data = np.load(source_file_path)\n",
    "\n",
    "            # Check if destination file exists\n",
    "            if os.path.exists(dest_file_path):\n",
    "                # Load existing data from destination file\n",
    "                dest_data = np.load(dest_file_path)\n",
    "                # Concatenate source data to destination data\n",
    "                combined_data = np.concatenate((dest_data, source_data))\n",
    "            else:\n",
    "                # If destination file does not exist, use source data as combined data\n",
    "                combined_data = source_data\n",
    "\n",
    "            # Save the combined data to the destination file\n",
    "            np.save(dest_file_path, combined_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenicsproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
